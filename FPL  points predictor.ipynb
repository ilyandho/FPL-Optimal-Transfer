{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from xgboost import XGBRegressor as xgb\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12,9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# For the linear model\n",
    "\n",
    "\n",
    "def Linear_regression(features_train, features_test, target_train, target_test):\n",
    "    # Before using our data, we need to do feature scaling and we opt for the 'standardization' method of scaling.\n",
    "    # The 'standardization' is avaliable thorugh the StandardScaler() method\n",
    "    # Transformers help in batching tasks in a pipepline. In this case, the data is scaled and then a linear regression model is fitted on the scaled data.\n",
    "    # We use a transformer that takes the regression model and the transformation method\n",
    "    # The TransformedTargetRegressor does the transformation and when we do the prediction, it automatically does the inverse transformation (scaling) and returns the values\n",
    "    model = TransformedTargetRegressor(\n",
    "        LinearRegression(), transformer=StandardScaler())\n",
    "\n",
    "    # fit the transofrmer on the train data\n",
    "    model.fit(features_train, target_train)\n",
    "\n",
    "    # With the model fitted, we can predict the total_points given the feature_train and feature_test set\n",
    "    pred_train = model.predict(features_train)\n",
    "    pred_test = model.predict(features_test)\n",
    "\n",
    "    # Evaluate the performance of the model on both sets using the root mean square error\n",
    "    train_RMSE = mean_squared_error(target_train, pred_train, squared=False)\n",
    "    test_RMSE = mean_squared_error(target_test, pred_test, squared=False)\n",
    "\n",
    "    # Get the score of the model or the coeeficient of determination i.e how much of the target value can be explained by the model.\n",
    "    # In this case, 0.6 implies that 60% of the variations in the target value can be explained by the model and 40% is not explainable\n",
    "    R2_train = model.score(features_train, target_train)\n",
    "    R2_test = model.score(features_test, target_test)\n",
    "\n",
    "    # If the test error significantly differs from the train error, then there is either overfitting or underfitting\n",
    "    # RMSE, just like the squared loss function that it derives from, effectively penalizes larger errors more severely.\n",
    "    print('Training set RMSE: {}'.format(train_RMSE))\n",
    "    print('Test set RMSE: {}'.format(test_RMSE))\n",
    "\n",
    "\n",
    "\n",
    "    print('Training set R2: {}'.format(R2_train))\n",
    "    print('Test set R2: {}'.format(R2_test))\n",
    "\n",
    "    # Carry out cross validation of the model.\n",
    "    # The evaluation method is the root mean square error\n",
    "    # The method expects a utility function (greater is better) and so the scoring function is the opposite of the the RMSE. Hence the -ve\n",
    "    tree_rmses = -cross_val_score(model, features_train, target_train,\n",
    "                                  scoring=\"neg_root_mean_squared_error\", cv=10)\n",
    "\n",
    "    print(pd.Series(tree_rmses).describe())\n",
    "\n",
    "    return {'train_RMSE': train_RMSE, 'test_RMSE': test_RMSE, 'cv_rmse': tree_rmses.mean(), 'R2_train': R2_train, 'R2_test': R2_test}\n",
    "\n",
    "\n",
    "# Decision Tree Model\n",
    "def DecisionTreeRegression(features_train, features_test, target_train, target_test):\n",
    "    # The DecisionTreeRegressor is passed as the model to the TransformedTreeRegressor together with the StandardScaler\n",
    "    model = TransformedTargetRegressor(\n",
    "        DecisionTreeRegressor(), transformer=StandardScaler())\n",
    "    model.fit(features_train, target_train)\n",
    "\n",
    "    pred_train = model.predict(features_train)\n",
    "    pred_test = model.predict(features_test)\n",
    "\n",
    "    train_RMSE = mean_squared_error(target_train, pred_train, squared=False)\n",
    "    test_RMSE = mean_squared_error(target_test, pred_test, squared=False)\n",
    "\n",
    "    R2_train = model.score(features_train, target_train)\n",
    "    R2_test = model.score(features_test, target_test)\n",
    "\n",
    "    print('Training set RMSE: {}'.format(train_RMSE))\n",
    "    print('Test set RMSE: {}'.format(test_RMSE))\n",
    "    print('Training set R2: {}'.format(R2_train))\n",
    "    print('Test set R2: {}'.format(R2_test))\n",
    "\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    tree_rmses = -cross_val_score(model, features_train, target_train,\n",
    "                                  scoring=\"neg_root_mean_squared_error\", cv=10)\n",
    "    print(pd.Series(tree_rmses).describe())\n",
    "    return {'train_RMSE': train_RMSE, 'test_RMSE': test_RMSE, 'cv_rmse': tree_rmses.mean(), 'R2_train': R2_train, 'R2_test': R2_test}\n",
    "\n",
    "\n",
    "# RandomForestRegressor\n",
    "def RandomForestRegression(features_train, features_test, target_train, target_test, hyperparameters):\n",
    "    # RandomForestRegressor is an ensemble method\n",
    "    # The TransformedTargetRegressor is passed the RandomForestRegressor model\n",
    "    # The RandomForestRegressor is passed some hyper-parameters such as;\n",
    "    # n_esimtaors: number of trees in the forest,\n",
    "    # max_depth: the maximum depth of the tree,\n",
    "    # criterion: the function to measure the quality of the split\n",
    "\n",
    "    model = TransformedTargetRegressor(RandomForestRegressor(\n",
    "        n_estimators=hyperparameters['n_estimators'],  max_depth=hyperparameters['max_depth'], criterion=hyperparameters['criterion'], random_state=18), transformer=StandardScaler())\n",
    "    model.fit(features_train, target_train)\n",
    "\n",
    "    pred_train = model.predict(features_train)\n",
    "    pred_test = model.predict(features_test)\n",
    "\n",
    "    train_RMSE = mean_squared_error(target_train, pred_train, squared=False)\n",
    "    test_RMSE = mean_squared_error(target_test, pred_test, squared=False)\n",
    "\n",
    "    R2_train = model.score(features_train, target_train)\n",
    "    R2_test = model.score(features_test, target_test)\n",
    "\n",
    "    # print('Training set RMSE: {}'.format(train_RMSE))\n",
    "    # print('Test set RMSE: {}'.format(test_RMSE))\n",
    "    # print('Training set R2: {}'.format(R2_train))\n",
    "    # print('Test set R2: {}'.format(R2_test))\n",
    "\n",
    "    tree_rmses = -cross_val_score(model, features_train, target_train,\n",
    "                                  scoring=\"neg_root_mean_squared_error\", cv=10)\n",
    "    print(pd.Series(tree_rmses).describe())\n",
    "\n",
    "    return {'train_RMSE': train_RMSE, 'test_RMSE': test_RMSE, 'cv_rmse': tree_rmses.mean(), 'R2_train': R2_train, 'R2_test': R2_test}\n",
    "\n",
    "\n",
    "def XGBoostRegression(features_train, features_test, target_train, target_test, hyperparameters):\n",
    "    regressor = xgb(learning_rate=hyperparameters[\"learning_rate\"],\n",
    "                    n_estimators=hyperparameters[\"n_estimators\"],\n",
    "                    max_depth=hyperparameters[\"max_depth\"],\n",
    "                    eval_metric='rmsle')\n",
    "\n",
    "    model = TransformedTargetRegressor(regressor, transformer=StandardScaler())\n",
    "\n",
    "\n",
    "    model.fit(features_train, target_train)\n",
    "\n",
    "    # =========================================================================\n",
    "    # To use early_stopping_rounds:\n",
    "    # \"Validation metric needs to improve at least once in every\n",
    "    # early_stopping_rounds round(s) to continue training.\"\n",
    "    # =========================================================================\n",
    "    # first perform a test/train split\n",
    "    # from sklearn.model_selection import train_test_split\n",
    "\n",
    "    # X_train,X_test,y_train,y_test = train_test_split(X_train,y_train, test_size = 0.2)\n",
    "    # model.fit(X_train, y_train, early_stopping_rounds=6, eval_set=[(X_test, y_test)], verbose=False)\n",
    "\n",
    "    # =========================================================================\n",
    "    # use the model to predict the prices for the test data\n",
    "    # =========================================================================\n",
    "    # predictions = model.predict(goalkeepers_splits['feature_test'])\n",
    "\n",
    "    pred_train = model.predict(features_train)\n",
    "    pred_test = model.predict(features_test)\n",
    "\n",
    "    train_RMSE = mean_squared_error(target_train,  pred_train, squared=False)\n",
    "    test_RMSE = mean_squared_error(target_test, pred_test, squared=False)\n",
    "\n",
    "    R2_train = model.score(features_train, target_train)\n",
    "    R2_test = model.score(features_test, target_test)\n",
    "\n",
    "    # print('Training set RMSE: {}'.format(train_RMSE))\n",
    "    # print('Test set RMSE: {}'.format(test_RMSE))\n",
    "    # print('Training set R2: {}'.format(R2_train))\n",
    "    # print('Test set R2: {}'.format(R2_test))\n",
    "\n",
    "    tree_rmses = -cross_val_score(model, features_train, target_train, scoring=\"neg_root_mean_squared_error\", cv=10)\n",
    "    pd.Series(tree_rmses).describe()\n",
    "\n",
    "    return {'train_RMSE': train_RMSE, 'test_RMSE': test_RMSE,  'cv_rmse': tree_rmses.mean(), 'R2_train': R2_train, 'R2_test': R2_test}\n",
    "\n",
    "\n",
    "def GridSearchParams(features_train, target_train):\n",
    "    # Instatiate the model\n",
    "    model = RandomForestRegressor()\n",
    "\n",
    "    param_grid = {'n_estimators': [8, 10, 12, 14, 16, 18, 20]}\n",
    "\n",
    "    # Define the possible values of the hyperparameter\n",
    "    grid = {\n",
    "        'n_estimators': [8, 10, 12, 14, 16, 18, 20, 200, 300, 400, 500],\n",
    "        'max_features': ['sqrt', 'log2'],\n",
    "        'max_depth': [4, 5, 6, 7, 8],\n",
    "        'criterion': ['squared_error', 'absolute_error', 'friedman_mse', 'poisson'],\n",
    "        'random_state': [18]\n",
    "    }\n",
    "\n",
    "    # Deine the model with cv=3 for a 3-fold cross validation\n",
    "    # GridSearchCV has the best_estimator_ parameter that returns the  estimator\n",
    "    # which gave highest score (or smallest loss if specified)\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        model, grid, cv=3, scoring='neg_root_mean_squared_error')\n",
    "    grid_search.fit(features_train, target_train)\n",
    "\n",
    "    # Get the best param combination\n",
    "    print(grid_search.best_estimator_)\n",
    "\n",
    "    return {'train_RMSE': train_RMSE, 'test_RMSE': test_RMSE, 'R2_train': R2_train, 'R2_test': R2_test}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that splits and returns features_train, features_test, target_train, target_test\n",
    "\n",
    "def split_data(data):\n",
    "    # Store the 'total_points' target in the 'player_target' variable\n",
    "    # and the rest in the player_features variable\n",
    "    player_target = data['total_points']\n",
    "    player_features = data.drop(\"total_points\", axis=1)\n",
    "\n",
    "    # The train_test_split function splits the set into train and test sets while maintain the same data distribution over both sets.\n",
    "    # It takes the feature and target sets and reutrns the respective train and test sets\n",
    "    features_train, features_test, target_train, target_test = train_test_split(\n",
    "        player_features, player_target, test_size=0.2)\n",
    "\n",
    "    return {'feature_train': features_train, 'features_test': features_test, 'target_train': target_train, 'target_test': target_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29679 entries, 0 to 29678\n",
      "Data columns (total 29 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   id                          29679 non-null  int64  \n",
      " 1   gw                          29679 non-null  int64  \n",
      " 2   team_h_difficulty           29679 non-null  int64  \n",
      " 3   team_a_difficulty           29679 non-null  int64  \n",
      " 4   position                    29679 non-null  int64  \n",
      " 5   minutes                     29679 non-null  int64  \n",
      " 6   goals_scored                29679 non-null  int64  \n",
      " 7   assists                     29679 non-null  int64  \n",
      " 8   clean_sheets                29679 non-null  int64  \n",
      " 9   goals_conceded              29679 non-null  int64  \n",
      " 10  own_goals                   29679 non-null  int64  \n",
      " 11  penalties_saved             29679 non-null  int64  \n",
      " 12  penalties_missed            29679 non-null  int64  \n",
      " 13  yellow_cards                29679 non-null  int64  \n",
      " 14  red_cards                   29679 non-null  int64  \n",
      " 15  saves                       29679 non-null  int64  \n",
      " 16  bonus                       29679 non-null  int64  \n",
      " 17  bps                         29679 non-null  int64  \n",
      " 18  influence                   29679 non-null  float64\n",
      " 19  creativity                  29679 non-null  float64\n",
      " 20  threat                      29679 non-null  float64\n",
      " 21  ict_index                   29679 non-null  float64\n",
      " 22  starts                      29679 non-null  int64  \n",
      " 23  expected_goals              29679 non-null  float64\n",
      " 24  expected_assists            29679 non-null  float64\n",
      " 25  expected_goal_involvements  29679 non-null  float64\n",
      " 26  expected_goals_conceded     29679 non-null  float64\n",
      " 27  total_points                29679 non-null  int64  \n",
      " 28  in_dreamteam                29679 non-null  bool   \n",
      "dtypes: bool(1), float64(8), int64(20)\n",
      "memory usage: 6.4 MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./content/fpl_player_data_new.csv').drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Separate the week to be predicted\n",
    "##\n",
    "def get_details(gw):\n",
    "    # player_data = pd.DataFrame(get_player_data(gw))\n",
    "\n",
    "    # Separate next gw's data\n",
    "    next_gw_data = df[df['gw'] == gw]\n",
    "\n",
    "    # Drop this data from the rest of data\n",
    "    player_data = df.drop(df[df['gw'] >= gw].index)\n",
    "\n",
    "    return player_data #, next_gw_data\n",
    "\n",
    "\n",
    "details = get_details(39)\n",
    "details.head()\n",
    "\n",
    "details.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3013, 25)\n",
      "(8487, 25)\n",
      "(11338, 25)\n",
      "(3397, 25)\n"
     ]
    }
   ],
   "source": [
    "player_data = details.copy()\n",
    "# next_gw_data = details[1]\n",
    "# Of the features, we want to use features that are available at the time the model is running.\n",
    "# This makes sure that the model only depends on games stats that are available before the match starts.\n",
    "# These will store in the 'attributes' variable and we will subsquently be using these for the rest of the work.\n",
    "attributes = ['id','gw','team_h_difficulty', 'team_a_difficulty', 'position', 'minutes',  'goals_scored',\n",
    "              'assists',  'clean_sheets',  'goals_conceded', 'own_goals', 'penalties_saved',\n",
    "              'penalties_missed', 'yellow_cards', 'red_cards', 'saves', 'bonus', 'bps', 'influence', 'creativity',\n",
    "              'threat', 'ict_index', 'starts','expected_goals', 'expected_assists',\n",
    "              'expected_goal_involvements', 'expected_goals_conceded', 'total_points']\n",
    "player_data = player_data[attributes]\n",
    "player_data\n",
    "\n",
    "def prev_3(feats, data): # create a feature that data in last 3 gws\n",
    "  data = data.copy()\n",
    "  data = data.sort_values(by=['id', 'gw'])  # Sort by ID and gameweek\n",
    "  for feat in feats:\n",
    "    data[feat+'_3'] = (\n",
    "        data.groupby(['id'])[feat]\n",
    "        .rolling(3, min_periods=1, closed='left').sum()).reset_index(level=0, drop=True).fillna(data[feat])\n",
    "  return data\n",
    "\n",
    "feats = ['starts','minutes',  'goals_scored',  'assists',  'clean_sheets',  'goals_conceded', 'own_goals', 'penalties_saved',\n",
    "        'penalties_missed', 'yellow_cards', 'red_cards', 'saves', 'bonus', 'bps', 'influence', 'creativity','threat']\n",
    "\n",
    "y = prev_3(feats, player_data)\n",
    "player_data_3 = y.drop(feats, axis=1)\n",
    "player_data_3\n",
    "\n",
    "\n",
    "working_data = player_data_3.loc[player_data_3['gw'] < 35]\n",
    "working_data = working_data.drop(['id','gw'], axis=1)\n",
    "\n",
    "working_data\n",
    "\n",
    "# Split data by positions\n",
    "df_gk = working_data.loc[working_data['position'] == 1].drop('position', axis='columns')\n",
    "print(df_gk.shape)\n",
    "\n",
    "df_def = working_data.loc[working_data['position'] == 2].drop('position', axis='columns')\n",
    "print(df_def.shape)\n",
    "\n",
    "df_mid = working_data.loc[working_data['position'] == 3].drop('position', axis='columns')\n",
    "print(df_mid.shape)\n",
    "\n",
    "df_for = working_data.loc[working_data['position'] == 4].drop('position', axis='columns')\n",
    "print(df_for.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goalkeepers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the gk data into train and test sets\n",
    "gk_splits = split_data(df_gk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set RMSE: 1.1728340864468927\n",
      "Test set RMSE: 1.196807044452891\n",
      "Training set R2: 0.6089983456306287\n",
      "Test set R2: 0.6030766074006457\n",
      "count    10.000000\n",
      "mean      1.187705\n",
      "std       0.179513\n",
      "min       0.957313\n",
      "25%       1.042141\n",
      "50%       1.177961\n",
      "75%       1.304479\n",
      "max       1.527836\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_gk_lin_reg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_RMSE</th>\n",
       "      <td>1.172834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_RMSE</th>\n",
       "      <td>1.196807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv_rmse</th>\n",
       "      <td>1.187705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2_train</th>\n",
       "      <td>0.608998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2_test</th>\n",
       "      <td>0.603077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            base_gk_lin_reg\n",
       "train_RMSE         1.172834\n",
       "test_RMSE          1.196807\n",
       "cv_rmse            1.187705\n",
       "R2_train           0.608998\n",
       "R2_test            0.603077"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_gk_lin_reg = Linear_regression(gk_splits['feature_train'], gk_splits['features_test'],\n",
    "                               gk_splits['target_train'], gk_splits['target_test'])\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "gk_evaluation_stats = pd.DataFrame({\"base_gk_lin_reg\": [base_gk_lin_reg['train_RMSE'], base_gk_lin_reg['test_RMSE'], base_gk_lin_reg['cv_rmse'], base_gk_lin_reg['R2_train'], base_gk_lin_reg['R2_test']]},\n",
    "                                                        index=(['train_RMSE', 'test_RMSE', 'cv_rmse', 'R2_train', 'R2_test']))\n",
    "\n",
    "gk_evaluation_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecisionTree Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set RMSE: 0.02032099570056468\n",
      "Test set RMSE: 1.5149895444010106\n",
      "Training set R2: 0.9998826196490033\n",
      "Test set R2: 0.36396986592575264\n",
      "count    10.000000\n",
      "mean      1.580270\n",
      "std       0.193995\n",
      "min       1.270477\n",
      "25%       1.428038\n",
      "50%       1.609732\n",
      "75%       1.709402\n",
      "max       1.852441\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_gk_lin_reg</th>\n",
       "      <th>base_gk_dt_reg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_RMSE</th>\n",
       "      <td>1.172834</td>\n",
       "      <td>0.020321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_RMSE</th>\n",
       "      <td>1.196807</td>\n",
       "      <td>1.514990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv_rmse</th>\n",
       "      <td>1.187705</td>\n",
       "      <td>1.580270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2_train</th>\n",
       "      <td>0.608998</td>\n",
       "      <td>0.999883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2_test</th>\n",
       "      <td>0.603077</td>\n",
       "      <td>0.363970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            base_gk_lin_reg  base_gk_dt_reg\n",
       "train_RMSE         1.172834        0.020321\n",
       "test_RMSE          1.196807        1.514990\n",
       "cv_rmse            1.187705        1.580270\n",
       "R2_train           0.608998        0.999883\n",
       "R2_test            0.603077        0.363970"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "base_gk_dt_reg = DecisionTreeRegression(gk_splits['feature_train'], gk_splits['features_test'],\n",
    "                               gk_splits['target_train'], gk_splits['target_test'])\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "gk_evaluation_stats = gk_evaluation_stats.assign(base_gk_dt_reg = [base_gk_dt_reg['train_RMSE'], base_gk_dt_reg['test_RMSE'], base_gk_dt_reg['cv_rmse'], base_gk_dt_reg['R2_train'], base_gk_dt_reg['R2_test']])\n",
    "\n",
    "gk_evaluation_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    10.000000\n",
      "mean      1.166375\n",
      "std       0.176366\n",
      "min       0.954854\n",
      "25%       1.028862\n",
      "50%       1.135168\n",
      "75%       1.272641\n",
      "max       1.484821\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_gk_lin_reg</th>\n",
       "      <th>base_gk_dt_reg</th>\n",
       "      <th>base_gk_rf_reg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_RMSE</th>\n",
       "      <td>1.172834</td>\n",
       "      <td>0.020321</td>\n",
       "      <td>0.719226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_RMSE</th>\n",
       "      <td>1.196807</td>\n",
       "      <td>1.514990</td>\n",
       "      <td>1.124639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv_rmse</th>\n",
       "      <td>1.187705</td>\n",
       "      <td>1.580270</td>\n",
       "      <td>1.166375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2_train</th>\n",
       "      <td>0.608998</td>\n",
       "      <td>0.999883</td>\n",
       "      <td>0.852960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2_test</th>\n",
       "      <td>0.603077</td>\n",
       "      <td>0.363970</td>\n",
       "      <td>0.649503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            base_gk_lin_reg  base_gk_dt_reg  base_gk_rf_reg\n",
       "train_RMSE         1.172834        0.020321        0.719226\n",
       "test_RMSE          1.196807        1.514990        1.124639\n",
       "cv_rmse            1.187705        1.580270        1.166375\n",
       "R2_train           0.608998        0.999883        0.852960\n",
       "R2_test            0.603077        0.363970        0.649503"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters = {\"criterion\": 'friedman_mse', \"max_depth\": 8, \"max_features\": 'sqrt', \"n_estimators\": 20}\n",
    "base_gk_rf_reg = RandomForestRegression(gk_splits['feature_train'], gk_splits['features_test'],\n",
    "                               gk_splits['target_train'], gk_splits['target_test'], hyperparameters)\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "gk_evaluation_stats = gk_evaluation_stats.assign(base_gk_rf_reg = [base_gk_rf_reg['train_RMSE'], base_gk_rf_reg['test_RMSE'], base_gk_rf_reg['cv_rmse'], base_gk_rf_reg['R2_train'], base_gk_rf_reg['R2_test']])\n",
    "\n",
    "gk_evaluation_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XgBoost Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_gk_lin_reg</th>\n",
       "      <th>base_gk_dt_reg</th>\n",
       "      <th>base_gk_rf_reg</th>\n",
       "      <th>base_gk_xgb_reg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_RMSE</th>\n",
       "      <td>1.172834</td>\n",
       "      <td>0.020321</td>\n",
       "      <td>0.719226</td>\n",
       "      <td>0.930634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_RMSE</th>\n",
       "      <td>1.196807</td>\n",
       "      <td>1.514990</td>\n",
       "      <td>1.124639</td>\n",
       "      <td>1.164099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv_rmse</th>\n",
       "      <td>1.187705</td>\n",
       "      <td>1.580270</td>\n",
       "      <td>1.166375</td>\n",
       "      <td>1.120339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2_train</th>\n",
       "      <td>0.608998</td>\n",
       "      <td>0.999883</td>\n",
       "      <td>0.852960</td>\n",
       "      <td>0.753814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2_test</th>\n",
       "      <td>0.603077</td>\n",
       "      <td>0.363970</td>\n",
       "      <td>0.649503</td>\n",
       "      <td>0.624475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            base_gk_lin_reg  base_gk_dt_reg  base_gk_rf_reg  base_gk_xgb_reg\n",
       "train_RMSE         1.172834        0.020321        0.719226         0.930634\n",
       "test_RMSE          1.196807        1.514990        1.124639         1.164099\n",
       "cv_rmse            1.187705        1.580270        1.166375         1.120339\n",
       "R2_train           0.608998        0.999883        0.852960         0.753814\n",
       "R2_test            0.603077        0.363970        0.649503         0.624475"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters = {'learning_rate': 0.02, 'max_depth': 4, 'n_estimators': 150}\n",
    "base_gk_xgb_reg = XGBoostRegression(gk_splits['feature_train'], gk_splits['features_test'], gk_splits['target_train'], gk_splits['target_test'], hyperparameters)\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "gk_evaluation_stats = gk_evaluation_stats.assign(base_gk_xgb_reg = [base_gk_xgb_reg['train_RMSE'], base_gk_xgb_reg['test_RMSE'], base_gk_xgb_reg['cv_rmse'], base_gk_xgb_reg['R2_train'], base_gk_xgb_reg['R2_test']])\n",
    "gk_evaluation_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defenders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the gk data into train and test sets\n",
    "def_splits = split_data(df_def)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set RMSE: 1.5249813490407387\n",
      "Test set RMSE: 1.5652622842115698\n",
      "Training set R2: 0.5269765934492253\n",
      "Test set R2: 0.5121506502167075\n",
      "count    10.000000\n",
      "mean      1.538822\n",
      "std       0.081757\n",
      "min       1.393108\n",
      "25%       1.490492\n",
      "50%       1.546916\n",
      "75%       1.595810\n",
      "max       1.642507\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_def_lin_reg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_RMSE</th>\n",
       "      <td>1.524981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_RMSE</th>\n",
       "      <td>1.565262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv_rmse</th>\n",
       "      <td>1.538822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2_train</th>\n",
       "      <td>0.526977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2_test</th>\n",
       "      <td>0.512151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            base_def_lin_reg\n",
       "train_RMSE          1.524981\n",
       "test_RMSE           1.565262\n",
       "cv_rmse             1.538822\n",
       "R2_train            0.526977\n",
       "R2_test             0.512151"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_def_lin_reg = Linear_regression(def_splits['feature_train'], def_splits['features_test'],\n",
    "                               def_splits['target_train'], def_splits['target_test'])\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "def_evaluation_stats = pd.DataFrame({\"base_def_lin_reg\": [base_def_lin_reg['train_RMSE'], base_def_lin_reg['test_RMSE'], base_def_lin_reg['cv_rmse'], base_def_lin_reg['R2_train'], base_def_lin_reg['R2_test']]},\n",
    "                                                        index=(['train_RMSE', 'test_RMSE', 'cv_rmse', 'R2_train', 'R2_test']))\n",
    "\n",
    "def_evaluation_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecisionTree Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set RMSE: 0.03877665485665551\n",
      "Test set RMSE: 1.9759407449226811\n",
      "Training set R2: 0.99969416002517\n",
      "Test set R2: 0.22257353226606158\n",
      "count    10.000000\n",
      "mean      2.136962\n",
      "std       0.117776\n",
      "min       2.004783\n",
      "25%       2.031961\n",
      "50%       2.112911\n",
      "75%       2.232871\n",
      "max       2.308998\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_def_lin_reg</th>\n",
       "      <th>base_def_dt_reg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_RMSE</th>\n",
       "      <td>1.524981</td>\n",
       "      <td>0.038777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_RMSE</th>\n",
       "      <td>1.565262</td>\n",
       "      <td>1.975941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv_rmse</th>\n",
       "      <td>1.538822</td>\n",
       "      <td>2.136962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2_train</th>\n",
       "      <td>0.526977</td>\n",
       "      <td>0.999694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2_test</th>\n",
       "      <td>0.512151</td>\n",
       "      <td>0.222574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            base_def_lin_reg  base_def_dt_reg\n",
       "train_RMSE          1.524981         0.038777\n",
       "test_RMSE           1.565262         1.975941\n",
       "cv_rmse             1.538822         2.136962\n",
       "R2_train            0.526977         0.999694\n",
       "R2_test             0.512151         0.222574"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_def_dt_reg = DecisionTreeRegression(def_splits['feature_train'], def_splits['features_test'],\n",
    "                               def_splits['target_train'], def_splits['target_test'])\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "def_evaluation_stats = def_evaluation_stats.assign(base_def_dt_reg = [base_def_dt_reg['train_RMSE'], base_def_dt_reg['test_RMSE'], base_def_dt_reg['cv_rmse'], base_def_dt_reg['R2_train'], base_def_dt_reg['R2_test']])\n",
    "\n",
    "def_evaluation_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    10.000000\n",
      "mean      1.504316\n",
      "std       0.103102\n",
      "min       1.333848\n",
      "25%       1.431162\n",
      "50%       1.499671\n",
      "75%       1.568373\n",
      "max       1.648174\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_def_lin_reg</th>\n",
       "      <th>base_def_dt_reg</th>\n",
       "      <th>base_def_rf_reg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_RMSE</th>\n",
       "      <td>1.524981</td>\n",
       "      <td>0.038777</td>\n",
       "      <td>1.160868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_RMSE</th>\n",
       "      <td>1.565262</td>\n",
       "      <td>1.975941</td>\n",
       "      <td>1.501912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv_rmse</th>\n",
       "      <td>1.538822</td>\n",
       "      <td>2.136962</td>\n",
       "      <td>1.504316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2_train</th>\n",
       "      <td>0.526977</td>\n",
       "      <td>0.999694</td>\n",
       "      <td>0.725893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2_test</th>\n",
       "      <td>0.512151</td>\n",
       "      <td>0.222574</td>\n",
       "      <td>0.550841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            base_def_lin_reg  base_def_dt_reg  base_def_rf_reg\n",
       "train_RMSE          1.524981         0.038777         1.160868\n",
       "test_RMSE           1.565262         1.975941         1.501912\n",
       "cv_rmse             1.538822         2.136962         1.504316\n",
       "R2_train            0.526977         0.999694         0.725893\n",
       "R2_test             0.512151         0.222574         0.550841"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters = {\"criterion\": 'friedman_mse', \"max_depth\": 8, \"max_features\": 'sqrt', \"n_estimators\": 20}\n",
    "base_def_rf_reg = RandomForestRegression(def_splits['feature_train'], def_splits['features_test'],\n",
    "                               def_splits['target_train'], def_splits['target_test'], hyperparameters)\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "def_evaluation_stats = def_evaluation_stats.assign(base_def_rf_reg = [base_def_rf_reg['train_RMSE'], base_def_rf_reg['test_RMSE'], base_def_rf_reg['cv_rmse'], base_def_rf_reg['R2_train'], base_def_rf_reg['R2_test']])\n",
    "\n",
    "def_evaluation_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XgBoost Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_def_lin_reg</th>\n",
       "      <th>base_def_dt_reg</th>\n",
       "      <th>base_def_rf_reg</th>\n",
       "      <th>base_def_xgb_reg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_RMSE</th>\n",
       "      <td>1.524981</td>\n",
       "      <td>0.038777</td>\n",
       "      <td>1.160868</td>\n",
       "      <td>1.348802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_RMSE</th>\n",
       "      <td>1.565262</td>\n",
       "      <td>1.975941</td>\n",
       "      <td>1.501912</td>\n",
       "      <td>1.503127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv_rmse</th>\n",
       "      <td>1.538822</td>\n",
       "      <td>2.136962</td>\n",
       "      <td>1.504316</td>\n",
       "      <td>1.494550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2_train</th>\n",
       "      <td>0.526977</td>\n",
       "      <td>0.999694</td>\n",
       "      <td>0.725893</td>\n",
       "      <td>0.629959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2_test</th>\n",
       "      <td>0.512151</td>\n",
       "      <td>0.222574</td>\n",
       "      <td>0.550841</td>\n",
       "      <td>0.550114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            base_def_lin_reg  base_def_dt_reg  base_def_rf_reg  \\\n",
       "train_RMSE          1.524981         0.038777         1.160868   \n",
       "test_RMSE           1.565262         1.975941         1.501912   \n",
       "cv_rmse             1.538822         2.136962         1.504316   \n",
       "R2_train            0.526977         0.999694         0.725893   \n",
       "R2_test             0.512151         0.222574         0.550841   \n",
       "\n",
       "            base_def_xgb_reg  \n",
       "train_RMSE          1.348802  \n",
       "test_RMSE           1.503127  \n",
       "cv_rmse             1.494550  \n",
       "R2_train            0.629959  \n",
       "R2_test             0.550114  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters = {'learning_rate': 0.02, 'max_depth': 4, 'n_estimators': 150}\n",
    "base_def_xgb_reg = XGBoostRegression(def_splits['feature_train'], def_splits['features_test'], def_splits['target_train'], def_splits['target_test'], hyperparameters)\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "def_evaluation_stats = def_evaluation_stats.assign(base_def_xgb_reg = [base_def_xgb_reg['train_RMSE'], base_def_xgb_reg['test_RMSE'], base_def_xgb_reg['cv_rmse'], base_def_xgb_reg['R2_train'], base_def_xgb_reg['R2_test']])\n",
    "def_evaluation_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Midfielders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the gk data into train and test sets\n",
    "mid_splits = split_data(df_mid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set RMSE: 1.2098073473659274\n",
      "Test set RMSE: 1.2032290894484599\n",
      "Training set R2: 0.7470669504915141\n",
      "Test set R2: 0.7503718389271532\n",
      "count    10.000000\n",
      "mean      1.218390\n",
      "std       0.065664\n",
      "min       1.137721\n",
      "25%       1.164484\n",
      "50%       1.201721\n",
      "75%       1.272718\n",
      "max       1.315138\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_mid_lin_reg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_RMSE</th>\n",
       "      <td>1.209807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_RMSE</th>\n",
       "      <td>1.203229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv_rmse</th>\n",
       "      <td>1.218390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2_train</th>\n",
       "      <td>0.747067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2_test</th>\n",
       "      <td>0.750372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            base_mid_lin_reg\n",
       "train_RMSE          1.209807\n",
       "test_RMSE           1.203229\n",
       "cv_rmse             1.218390\n",
       "R2_train            0.747067\n",
       "R2_test             0.750372"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_mid_lin_reg = Linear_regression(mid_splits['feature_train'], mid_splits['features_test'],\n",
    "                               mid_splits['target_train'], mid_splits['target_test'])\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "mid_evaluation_stats = pd.DataFrame({\"base_mid_lin_reg\": [base_mid_lin_reg['train_RMSE'], base_mid_lin_reg['test_RMSE'], base_mid_lin_reg['cv_rmse'], base_mid_lin_reg['R2_train'], base_mid_lin_reg['R2_test']]},\n",
    "                                                        index=(['train_RMSE', 'test_RMSE', 'cv_rmse', 'R2_train', 'R2_test']))\n",
    "\n",
    "mid_evaluation_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecisionTree Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set RMSE: 0.04357520940014326\n",
      "Test set RMSE: 1.6585840200664186\n",
      "Training set R2: 0.99967186533691\n",
      "Test set R2: 0.5256795109648773\n",
      "count    10.000000\n",
      "mean      1.649889\n",
      "std       0.103610\n",
      "min       1.464033\n",
      "25%       1.573726\n",
      "50%       1.658273\n",
      "75%       1.733577\n",
      "max       1.768623\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_mid_lin_reg</th>\n",
       "      <th>base_mid_dt_reg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_RMSE</th>\n",
       "      <td>1.209807</td>\n",
       "      <td>0.043575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_RMSE</th>\n",
       "      <td>1.203229</td>\n",
       "      <td>1.658584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv_rmse</th>\n",
       "      <td>1.218390</td>\n",
       "      <td>1.649889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2_train</th>\n",
       "      <td>0.747067</td>\n",
       "      <td>0.999672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2_test</th>\n",
       "      <td>0.750372</td>\n",
       "      <td>0.525680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            base_mid_lin_reg  base_mid_dt_reg\n",
       "train_RMSE          1.209807         0.043575\n",
       "test_RMSE           1.203229         1.658584\n",
       "cv_rmse             1.218390         1.649889\n",
       "R2_train            0.747067         0.999672\n",
       "R2_test             0.750372         0.525680"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_mid_dt_reg = DecisionTreeRegression(mid_splits['feature_train'], mid_splits['features_test'],\n",
    "                               mid_splits['target_train'], mid_splits['target_test'])\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "mid_evaluation_stats = mid_evaluation_stats.assign(base_mid_dt_reg = [base_mid_dt_reg['train_RMSE'], base_mid_dt_reg['test_RMSE'], base_mid_dt_reg['cv_rmse'], base_mid_dt_reg['R2_train'], base_mid_dt_reg['R2_test']])\n",
    "\n",
    "mid_evaluation_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    10.000000\n",
      "mean      1.158930\n",
      "std       0.056503\n",
      "min       1.084087\n",
      "25%       1.123883\n",
      "50%       1.147565\n",
      "75%       1.166157\n",
      "max       1.256046\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_mid_lin_reg</th>\n",
       "      <th>base_mid_dt_reg</th>\n",
       "      <th>base_mid_rf_reg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_RMSE</th>\n",
       "      <td>1.209807</td>\n",
       "      <td>0.043575</td>\n",
       "      <td>0.819880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_RMSE</th>\n",
       "      <td>1.203229</td>\n",
       "      <td>1.658584</td>\n",
       "      <td>1.161005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv_rmse</th>\n",
       "      <td>1.218390</td>\n",
       "      <td>1.649889</td>\n",
       "      <td>1.158930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2_train</th>\n",
       "      <td>0.747067</td>\n",
       "      <td>0.999672</td>\n",
       "      <td>0.883836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2_test</th>\n",
       "      <td>0.750372</td>\n",
       "      <td>0.525680</td>\n",
       "      <td>0.767585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            base_mid_lin_reg  base_mid_dt_reg  base_mid_rf_reg\n",
       "train_RMSE          1.209807         0.043575         0.819880\n",
       "test_RMSE           1.203229         1.658584         1.161005\n",
       "cv_rmse             1.218390         1.649889         1.158930\n",
       "R2_train            0.747067         0.999672         0.883836\n",
       "R2_test             0.750372         0.525680         0.767585"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters = {\"criterion\": 'friedman_mse', \"max_depth\": 8, \"max_features\": 'sqrt', \"n_estimators\": 20}\n",
    "base_mid_rf_reg = RandomForestRegression(mid_splits['feature_train'], mid_splits['features_test'],\n",
    "                               mid_splits['target_train'], mid_splits['target_test'], hyperparameters)\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "mid_evaluation_stats = mid_evaluation_stats.assign(base_mid_rf_reg = [base_mid_rf_reg['train_RMSE'], base_mid_rf_reg['test_RMSE'], base_mid_rf_reg['cv_rmse'], base_mid_rf_reg['R2_train'], base_mid_rf_reg['R2_test']])\n",
    "\n",
    "mid_evaluation_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XgBoost Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_mid_lin_reg</th>\n",
       "      <th>base_mid_dt_reg</th>\n",
       "      <th>base_mid_rf_reg</th>\n",
       "      <th>base_mid_xgb_reg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_RMSE</th>\n",
       "      <td>1.209807</td>\n",
       "      <td>0.043575</td>\n",
       "      <td>0.819880</td>\n",
       "      <td>1.025178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_RMSE</th>\n",
       "      <td>1.203229</td>\n",
       "      <td>1.658584</td>\n",
       "      <td>1.161005</td>\n",
       "      <td>1.162537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv_rmse</th>\n",
       "      <td>1.218390</td>\n",
       "      <td>1.649889</td>\n",
       "      <td>1.158930</td>\n",
       "      <td>1.163555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2_train</th>\n",
       "      <td>0.747067</td>\n",
       "      <td>0.999672</td>\n",
       "      <td>0.883836</td>\n",
       "      <td>0.818377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2_test</th>\n",
       "      <td>0.750372</td>\n",
       "      <td>0.525680</td>\n",
       "      <td>0.767585</td>\n",
       "      <td>0.766971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            base_mid_lin_reg  base_mid_dt_reg  base_mid_rf_reg  \\\n",
       "train_RMSE          1.209807         0.043575         0.819880   \n",
       "test_RMSE           1.203229         1.658584         1.161005   \n",
       "cv_rmse             1.218390         1.649889         1.158930   \n",
       "R2_train            0.747067         0.999672         0.883836   \n",
       "R2_test             0.750372         0.525680         0.767585   \n",
       "\n",
       "            base_mid_xgb_reg  \n",
       "train_RMSE          1.025178  \n",
       "test_RMSE           1.162537  \n",
       "cv_rmse             1.163555  \n",
       "R2_train            0.818377  \n",
       "R2_test             0.766971  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters = {'learning_rate': 0.02, 'max_depth': 4, 'n_estimators': 150}\n",
    "base_mid_xgb_reg = XGBoostRegression(mid_splits['feature_train'], mid_splits['features_test'], mid_splits['target_train'], mid_splits['target_test'], hyperparameters)\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "mid_evaluation_stats = mid_evaluation_stats.assign(base_mid_xgb_reg = [base_mid_xgb_reg['train_RMSE'], base_mid_xgb_reg['test_RMSE'], base_mid_xgb_reg['cv_rmse'], base_mid_xgb_reg['R2_train'], base_mid_xgb_reg['R2_test']])\n",
    "mid_evaluation_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forwards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the gk data into train and test sets\n",
    "for_splits = split_data(df_for)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set RMSE: 1.1256544582787864\n",
      "Test set RMSE: 1.2075563713334732\n",
      "Training set R2: 0.8014221711416641\n",
      "Test set R2: 0.8087245466214488\n",
      "count    10.000000\n",
      "mean      1.142576\n",
      "std       0.179193\n",
      "min       0.892144\n",
      "25%       1.029291\n",
      "50%       1.107164\n",
      "75%       1.266632\n",
      "max       1.432373\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_for_lin_reg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_RMSE</th>\n",
       "      <td>1.125654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_RMSE</th>\n",
       "      <td>1.207556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv_rmse</th>\n",
       "      <td>1.142576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2_train</th>\n",
       "      <td>0.801422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2_test</th>\n",
       "      <td>0.808725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            base_for_lin_reg\n",
       "train_RMSE          1.125654\n",
       "test_RMSE           1.207556\n",
       "cv_rmse             1.142576\n",
       "R2_train            0.801422\n",
       "R2_test             0.808725"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_for_lin_reg = Linear_regression(for_splits['feature_train'], for_splits['features_test'],\n",
    "                               for_splits['target_train'], for_splits['target_test'])\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "for_evaluation_stats = pd.DataFrame({\"base_for_lin_reg\": [base_for_lin_reg['train_RMSE'], base_for_lin_reg['test_RMSE'], base_for_lin_reg['cv_rmse'], base_for_lin_reg['R2_train'], base_for_lin_reg['R2_test']]},\n",
    "                                                        index=(['train_RMSE', 'test_RMSE', 'cv_rmse', 'R2_train', 'R2_test']))\n",
    "\n",
    "for_evaluation_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecisionTree Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set RMSE: 0.03315153014374723\n",
      "Test set RMSE: 1.5820683639054944\n",
      "Training set R2: 0.9998277624958662\n",
      "Test set R2: 0.6716818401289917\n",
      "count    10.000000\n",
      "mean      1.582113\n",
      "std       0.191698\n",
      "min       1.325655\n",
      "25%       1.442529\n",
      "50%       1.578952\n",
      "75%       1.700946\n",
      "max       1.902612\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_for_lin_reg</th>\n",
       "      <th>base_for_dt_reg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_RMSE</th>\n",
       "      <td>1.125654</td>\n",
       "      <td>0.033152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_RMSE</th>\n",
       "      <td>1.207556</td>\n",
       "      <td>1.582068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv_rmse</th>\n",
       "      <td>1.142576</td>\n",
       "      <td>1.582113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2_train</th>\n",
       "      <td>0.801422</td>\n",
       "      <td>0.999828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2_test</th>\n",
       "      <td>0.808725</td>\n",
       "      <td>0.671682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            base_for_lin_reg  base_for_dt_reg\n",
       "train_RMSE          1.125654         0.033152\n",
       "test_RMSE           1.207556         1.582068\n",
       "cv_rmse             1.142576         1.582113\n",
       "R2_train            0.801422         0.999828\n",
       "R2_test             0.808725         0.671682"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_for_dt_reg = DecisionTreeRegression(for_splits['feature_train'], for_splits['features_test'],\n",
    "                               for_splits['target_train'], for_splits['target_test'])\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "for_evaluation_stats = for_evaluation_stats.assign(base_for_dt_reg = [base_for_dt_reg['train_RMSE'], base_for_dt_reg['test_RMSE'], base_for_dt_reg['cv_rmse'], base_for_dt_reg['R2_train'], base_for_dt_reg['R2_test']])\n",
    "\n",
    "for_evaluation_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    10.000000\n",
      "mean      1.147101\n",
      "std       0.179934\n",
      "min       0.925272\n",
      "25%       1.005037\n",
      "50%       1.102775\n",
      "75%       1.282053\n",
      "max       1.471461\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_for_lin_reg</th>\n",
       "      <th>base_for_dt_reg</th>\n",
       "      <th>base_for_rf_reg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_RMSE</th>\n",
       "      <td>1.125654</td>\n",
       "      <td>0.033152</td>\n",
       "      <td>0.640831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_RMSE</th>\n",
       "      <td>1.207556</td>\n",
       "      <td>1.582068</td>\n",
       "      <td>1.139573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv_rmse</th>\n",
       "      <td>1.142576</td>\n",
       "      <td>1.582113</td>\n",
       "      <td>1.147101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2_train</th>\n",
       "      <td>0.801422</td>\n",
       "      <td>0.999828</td>\n",
       "      <td>0.935641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2_test</th>\n",
       "      <td>0.808725</td>\n",
       "      <td>0.671682</td>\n",
       "      <td>0.829655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            base_for_lin_reg  base_for_dt_reg  base_for_rf_reg\n",
       "train_RMSE          1.125654         0.033152         0.640831\n",
       "test_RMSE           1.207556         1.582068         1.139573\n",
       "cv_rmse             1.142576         1.582113         1.147101\n",
       "R2_train            0.801422         0.999828         0.935641\n",
       "R2_test             0.808725         0.671682         0.829655"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters = {\"criterion\": 'friedman_mse', \"max_depth\": 8, \"max_features\": 'sqrt', \"n_estimators\": 20}\n",
    "base_for_rf_reg = RandomForestRegression(for_splits['feature_train'], for_splits['features_test'],\n",
    "                               for_splits['target_train'], for_splits['target_test'], hyperparameters)\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "for_evaluation_stats = for_evaluation_stats.assign(base_for_rf_reg = [base_for_rf_reg['train_RMSE'], base_for_rf_reg['test_RMSE'], base_for_rf_reg['cv_rmse'], base_for_rf_reg['R2_train'], base_for_rf_reg['R2_test']])\n",
    "\n",
    "for_evaluation_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XgBoost Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_for_lin_reg</th>\n",
       "      <th>base_for_dt_reg</th>\n",
       "      <th>base_for_rf_reg</th>\n",
       "      <th>base_for_xgb_reg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_RMSE</th>\n",
       "      <td>1.125654</td>\n",
       "      <td>0.033152</td>\n",
       "      <td>0.640831</td>\n",
       "      <td>0.862736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_RMSE</th>\n",
       "      <td>1.207556</td>\n",
       "      <td>1.582068</td>\n",
       "      <td>1.139573</td>\n",
       "      <td>1.278661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv_rmse</th>\n",
       "      <td>1.142576</td>\n",
       "      <td>1.582113</td>\n",
       "      <td>1.147101</td>\n",
       "      <td>1.169952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2_train</th>\n",
       "      <td>0.801422</td>\n",
       "      <td>0.999828</td>\n",
       "      <td>0.935641</td>\n",
       "      <td>0.883352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2_test</th>\n",
       "      <td>0.808725</td>\n",
       "      <td>0.671682</td>\n",
       "      <td>0.829655</td>\n",
       "      <td>0.785536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            base_for_lin_reg  base_for_dt_reg  base_for_rf_reg  \\\n",
       "train_RMSE          1.125654         0.033152         0.640831   \n",
       "test_RMSE           1.207556         1.582068         1.139573   \n",
       "cv_rmse             1.142576         1.582113         1.147101   \n",
       "R2_train            0.801422         0.999828         0.935641   \n",
       "R2_test             0.808725         0.671682         0.829655   \n",
       "\n",
       "            base_for_xgb_reg  \n",
       "train_RMSE          0.862736  \n",
       "test_RMSE           1.278661  \n",
       "cv_rmse             1.169952  \n",
       "R2_train            0.883352  \n",
       "R2_test             0.785536  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters = {'learning_rate': 0.02, 'max_depth': 4, 'n_estimators': 150}\n",
    "base_for_xgb_reg = XGBoostRegression(for_splits['feature_train'], for_splits['features_test'], for_splits['target_train'], for_splits['target_test'], hyperparameters)\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "for_evaluation_stats = for_evaluation_stats.assign(base_for_xgb_reg = [base_for_xgb_reg['train_RMSE'], base_for_xgb_reg['test_RMSE'], base_for_xgb_reg['cv_rmse'], base_for_xgb_reg['R2_train'], base_for_xgb_reg['R2_test']])\n",
    "for_evaluation_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goalkeepers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VarianceThreshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VT_scaler = StandardScaler()\n",
    "VT_scaler.fit(gk_splits['feature_train'])\n",
    "df_gk_train_scaled = pd.DataFrame(VT_scaler.fit_transform(gk_splits['feature_train']), columns=gk_splits['feature_train'].columns)\n",
    "df_gk_test_scaled = pd.DataFrame(VT_scaler.transform(gk_splits['features_test']), columns=gk_splits['features_test'].columns)\n",
    "\n",
    "selector = VarianceThreshold(threshold = 0.1)\n",
    "selector.fit_transform(df_gk_train_scaled)\n",
    "\n",
    "gk_threshold_columns = df_gk_train_scaled.columns[selector.get_support()]\n",
    "\n",
    "gk_threshold_train = df_gk_train_scaled[gk_threshold_columns]\n",
    "gk_threshold_test = df_gk_test_scaled[gk_threshold_columns]\n",
    "\n",
    "gk_threshold_train.shape, gk_threshold_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model(VT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linear Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VarT_gk_lin_reg = Linear_regression(gk_threshold_train, gk_threshold_test,\n",
    "                               gk_splits['target_train'], gk_splits['target_test'])\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "gk_evaluation_stats = gk_evaluation_stats.assign(VarT_gk_lin_reg =  [VarT_gk_lin_reg['train_RMSE'], VarT_gk_lin_reg['test_RMSE'], VarT_gk_lin_reg['cv_rmse'], VarT_gk_lin_reg['R2_train'], VarT_gk_lin_reg['R2_test']])\n",
    "\n",
    "gk_evaluation_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DecisionTree Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VarT_gk_dt_reg = DecisionTreeRegression(gk_threshold_train, gk_threshold_test,\n",
    "                               gk_splits['target_train'], gk_splits['target_test'])\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "gk_evaluation_stats = gk_evaluation_stats.assign(VarT_gk_dt_reg = [VarT_gk_dt_reg['train_RMSE'], VarT_gk_dt_reg['test_RMSE'], VarT_gk_dt_reg['cv_rmse'], VarT_gk_dt_reg['R2_train'], VarT_gk_dt_reg['R2_test']])\n",
    "\n",
    "gk_evaluation_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RandomForest Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\"criterion\": 'friedman_mse', \"max_depth\": 8, \"max_features\": 'sqrt', \"n_estimators\": 20}\n",
    "VarT_gk_rf_reg = RandomForestRegression(gk_threshold_train, gk_threshold_test,\n",
    "                               gk_splits['target_train'], gk_splits['target_test'], hyperparameters)\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "gk_evaluation_stats = gk_evaluation_stats.assign(VarT_gk_rf_reg = [VarT_gk_rf_reg['train_RMSE'], VarT_gk_rf_reg['test_RMSE'], VarT_gk_rf_reg['cv_rmse'], VarT_gk_rf_reg['R2_train'], VarT_gk_rf_reg['R2_test']])\n",
    "\n",
    "gk_evaluation_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XgBoost Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {'learning_rate': 0.02, 'max_depth': 4, 'n_estimators': 150}\n",
    "VarT_gk_xgb_reg = XGBoostRegression(gk_threshold_train, gk_threshold_test, gk_splits['target_train'], gk_splits['target_test'], hyperparameters)\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "gk_evaluation_stats = gk_evaluation_stats.assign(VarT_gk_xgb_reg = [VarT_gk_xgb_reg['train_RMSE'], VarT_gk_xgb_reg['test_RMSE'], VarT_gk_xgb_reg['cv_rmse'], VarT_gk_xgb_reg['R2_train'], VarT_gk_xgb_reg['R2_test']])\n",
    "gk_evaluation_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection techniques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-best features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "\n",
    "k_rf_model = RandomForestRegressor(n_estimators=20,  max_depth=8, criterion='friedman_mse', max_features='sqrt', random_state=18)\n",
    "\n",
    "score_list  = []\n",
    "\n",
    "for k in range(1, 21):\n",
    "  selector = SelectKBest(mutual_info_regression, k=k)\n",
    "  k_sel_X_train =  selector.fit_transform(gk_threshold_train, gk_splits['target_train'])\n",
    "\n",
    "  k_rf_model.fit(k_sel_X_train, gk_splits['target_train'])\n",
    "\n",
    "  k_sel_cols = gk_threshold_train.columns[selector.get_support()]\n",
    "  k_sel_X_test = gk_threshold_test[k_sel_cols]\n",
    "  score = round(k_rf_model.score(k_sel_X_test.values, gk_splits['target_test'] ), 3)\n",
    "\n",
    "  score_list.append(score)\n",
    "print(score_list, score_list.index(max(score_list)))\n",
    "num_of_feat = score_list.index(max(score_list)) # find the highest score. We will use  that as the value of k\n",
    "\n",
    "selector = SelectKBest(mutual_info_regression, k=num_of_feat+1)\n",
    "selector.fit_transform(gk_threshold_train, gk_splits['target_train'])\n",
    "\n",
    "sel_feats = selector.get_feature_names_out()\n",
    "k_sel_X_train = gk_threshold_train[sel_feats]\n",
    "k_sel_X_test = gk_threshold_test[sel_feats]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model (KBest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Linear Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "KBest_gk_lin_reg = Linear_regression(k_sel_X_train, k_sel_X_test,\n",
    "                               gk_splits['target_train'], gk_splits['target_test'])\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "gk_evaluation_stats = gk_evaluation_stats.assign(KBest_gk_lin_reg =  [KBest_gk_lin_reg['train_RMSE'], KBest_gk_lin_reg['test_RMSE'], KBest_gk_lin_reg['cv_rmse'], KBest_gk_lin_reg['R2_train'], KBest_gk_lin_reg['R2_test']])\n",
    "\n",
    "gk_evaluation_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### DecisionTree Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KBest_gk_dt_reg = DecisionTreeRegression(k_sel_X_train, k_sel_X_test,\n",
    "                               gk_splits['target_train'], gk_splits['target_test'])\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "gk_evaluation_stats = gk_evaluation_stats.assign(KBest_gk_dt_reg = [KBest_gk_dt_reg['train_RMSE'], KBest_gk_dt_reg['test_RMSE'], KBest_gk_dt_reg['cv_rmse'], KBest_gk_dt_reg['R2_train'], KBest_gk_dt_reg['R2_test']])\n",
    "\n",
    "gk_evaluation_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### RandomForest Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\"criterion\": 'friedman_mse', \"max_depth\": 8, \"max_features\": 'sqrt', \"n_estimators\": 20}\n",
    "KBest_gk_rf_reg = RandomForestRegression(k_sel_X_train, k_sel_X_test,\n",
    "                               gk_splits['target_train'], gk_splits['target_test'], hyperparameters)\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "gk_evaluation_stats = gk_evaluation_stats.assign(KBest_gk_rf_reg = [KBest_gk_rf_reg['train_RMSE'], KBest_gk_rf_reg['test_RMSE'], KBest_gk_rf_reg['cv_rmse'], KBest_gk_rf_reg['R2_train'], KBest_gk_rf_reg['R2_test']])\n",
    "\n",
    "gk_evaluation_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### XgBoost Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {'learning_rate': 0.02, 'max_depth': 4, 'n_estimators': 150}\n",
    "KBest_gk_xgb_reg = XGBoostRegression(k_sel_X_train, k_sel_X_test, gk_splits['target_train'], gk_splits['target_test'], hyperparameters)\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "gk_evaluation_stats = gk_evaluation_stats.assign(KBest_gk_xgb_reg = [KBest_gk_xgb_reg['train_RMSE'], KBest_gk_xgb_reg['test_RMSE'], KBest_gk_xgb_reg['cv_rmse'], KBest_gk_xgb_reg['R2_train'], KBest_gk_xgb_reg['R2_test']])\n",
    "gk_evaluation_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mutual Information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "# gk_sel_X_train\n",
    "mutual_info = mutual_info_regression(k_sel_X_train, gk_splits['target_train'])\n",
    "mutual_info\n",
    "\n",
    "mutual_info = pd.Series(mutual_info)\n",
    "mutual_info.index = k_sel_X_train.columns\n",
    "mutual_info.sort_values(ascending=False)\n",
    "\n",
    "mutual_info.sort_values(ascending=False).plot.bar(figsize=(15,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Select to 20% perct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectPercentile\n",
    "\n",
    "## Selecting the top 20 percentile\n",
    "selected_top_columns = SelectPercentile(mutual_info_regression, percentile=50)\n",
    "selected_top_columns.fit(k_sel_X_train, gk_splits['target_train'])\n",
    "\n",
    "selected_top_columns.get_support()\n",
    "\n",
    "gk_20_columns = k_sel_X_train.columns[selected_top_columns.get_support()]\n",
    "\n",
    "gk_20_train = k_sel_X_train[gk_20_columns]\n",
    "gk_20_test = k_sel_X_test[gk_20_columns]\n",
    "\n",
    "\n",
    "gk_20_train.shape, gk_20_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model (MI)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Linear Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MI_gk_lin_reg = Linear_regression(gk_20_train, gk_20_test,\n",
    "                               gk_splits['target_train'], gk_splits['target_test'])\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "gk_evaluation_stats = gk_evaluation_stats.assign(MI_gk_lin_reg =  [MI_gk_lin_reg['train_RMSE'], MI_gk_lin_reg['test_RMSE'], MI_gk_lin_reg['cv_rmse'], MI_gk_lin_reg['R2_train'], MI_gk_lin_reg['R2_test']])\n",
    "\n",
    "gk_evaluation_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###### DecisionTree Model\n",
    "\n",
    "MI_gk_dt_reg = DecisionTreeRegression(gk_20_train, gk_20_test,\n",
    "                               gk_splits['target_train'], gk_splits['target_test'])\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "gk_evaluation_stats = gk_evaluation_stats.assign(MI_gk_dt_reg = [MI_gk_dt_reg['train_RMSE'], MI_gk_dt_reg['test_RMSE'], MI_gk_dt_reg['cv_rmse'], MI_gk_dt_reg['R2_train'], MI_gk_dt_reg['R2_test']])\n",
    "\n",
    "gk_evaluation_stats\n",
    "\n",
    "\n",
    "\n",
    "###### RandomForest Model\n",
    "\n",
    "hyperparameters = {\"criterion\": 'friedman_mse', \"max_depth\": 8, \"max_features\": 'sqrt', \"n_estimators\": 20}\n",
    "MI_gk_rf_reg = RandomForestRegression(gk_20_train, gk_20_test,\n",
    "                               gk_splits['target_train'], gk_splits['target_test'], hyperparameters)\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "gk_evaluation_stats = gk_evaluation_stats.assign(MI_gk_rf_reg = [MI_gk_rf_reg['train_RMSE'], MI_gk_rf_reg['test_RMSE'], MI_gk_rf_reg['cv_rmse'], MI_gk_rf_reg['R2_train'], MI_gk_rf_reg['R2_test']])\n",
    "\n",
    "gk_evaluation_stats\n",
    "\n",
    "###### XgBoost Model\n",
    "\n",
    "hyperparameters = {'learning_rate': 0.02, 'max_depth': 4, 'n_estimators': 150}\n",
    "MI_gk_xgb_reg = XGBoostRegression(k_sel_X_train, k_sel_X_test, gk_splits['target_train'], gk_splits['target_test'], hyperparameters)\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "gk_evaluation_stats = gk_evaluation_stats.assign(MI_gk_xgb_reg = [MI_gk_xgb_reg['train_RMSE'], MI_gk_xgb_reg['test_RMSE'], MI_gk_xgb_reg['cv_rmse'], MI_gk_xgb_reg['R2_train'], MI_gk_xgb_reg['R2_test']])\n",
    "gk_evaluation_stats\n",
    "\n",
    "## Defenders\n",
    "\n",
    "\n",
    "### VarianceThreshold\n",
    "\n",
    "VT_scaler = StandardScaler()\n",
    "df_def_train_scaled = pd.DataFrame(VT_scaler.fit_transform(def_splits['feature_train']), columns=def_splits['feature_train'].columns)\n",
    "df_def_test_scaled = pd.DataFrame(VT_scaler.transform(def_splits['features_test']), columns=def_splits['features_test'].columns)\n",
    "\n",
    "selector = VarianceThreshold(threshold = 0.1)\n",
    "selector.fit_transform(df_def_train_scaled)\n",
    "\n",
    "def_threshold_columns = df_def_train_scaled.columns[selector.get_support()]\n",
    "\n",
    "def_threshold_train = df_def_train_scaled[def_threshold_columns]\n",
    "def_threshold_test = df_def_test_scaled[def_threshold_columns]\n",
    "\n",
    "def_threshold_train.shape, def_threshold_test.shape\n",
    "\n",
    "#### Model(VT)\n",
    "\n",
    "##### Linear Model\n",
    "\n",
    "\n",
    "VarT_def_lin_reg = Linear_regression(def_threshold_train, def_threshold_test,\n",
    "                               def_splits['target_train'], def_splits['target_test'])\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "def_evaluation_stats = def_evaluation_stats.assign(VarT_def_lin_reg =  [VarT_def_lin_reg['train_RMSE'], VarT_def_lin_reg['test_RMSE'], VarT_def_lin_reg['cv_rmse'], VarT_def_lin_reg['R2_train'], VarT_def_lin_reg['R2_test']])\n",
    "\n",
    "def_evaluation_stats\n",
    "\n",
    "##### DecisionTree Model\n",
    "\n",
    "VarT_def_dt_reg = DecisionTreeRegression(def_threshold_train, def_threshold_test,\n",
    "                               def_splits['target_train'], def_splits['target_test'])\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "def_evaluation_stats = def_evaluation_stats.assign(VarT_def_dt_reg = [VarT_def_dt_reg['train_RMSE'], VarT_def_dt_reg['test_RMSE'], VarT_def_dt_reg['cv_rmse'], VarT_def_dt_reg['R2_train'], VarT_def_dt_reg['R2_test']])\n",
    "\n",
    "def_evaluation_stats\n",
    "\n",
    "\n",
    "\n",
    "##### RandomForest Model\n",
    "\n",
    "hyperparameters = {\"criterion\": 'friedman_mse', \"max_depth\": 8, \"max_features\": 'sqrt', \"n_estimators\": 20}\n",
    "VarT_def_rf_reg = RandomForestRegression(def_threshold_train, def_threshold_test,\n",
    "                               def_splits['target_train'], def_splits['target_test'], hyperparameters)\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "def_evaluation_stats = def_evaluation_stats.assign(VarT_def_rf_reg = [VarT_def_rf_reg['train_RMSE'], VarT_def_rf_reg['test_RMSE'], VarT_def_rf_reg['cv_rmse'], VarT_def_rf_reg['R2_train'], VarT_def_rf_reg['R2_test']])\n",
    "\n",
    "def_evaluation_stats\n",
    "\n",
    "##### XgBoost Model\n",
    "\n",
    "hyperparameters = {'learning_rate': 0.02, 'max_depth': 4, 'n_estimators': 150}\n",
    "VarT_def_xgb_reg = XGBoostRegression(def_threshold_train, def_threshold_test, def_splits['target_train'], def_splits['target_test'], hyperparameters)\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "def_evaluation_stats = def_evaluation_stats.assign(VarT_def_xgb_reg = [VarT_def_xgb_reg['train_RMSE'], VarT_def_xgb_reg['test_RMSE'], VarT_def_xgb_reg['cv_rmse'], VarT_def_xgb_reg['R2_train'], VarT_def_xgb_reg['R2_test']])\n",
    "def_evaluation_stats\n",
    "\n",
    "### Feature selection techniques\n",
    "\n",
    "#### K-best features\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "\n",
    "k_rf_model = RandomForestRegressor(n_estimators=20,  max_depth=8, criterion='friedman_mse', max_features='sqrt', random_state=18)\n",
    "\n",
    "score_list  = []\n",
    "\n",
    "for k in range(1, 21):\n",
    "  selector = SelectKBest(mutual_info_regression, k=k)\n",
    "  k_sel_X_train =  selector.fit_transform(def_threshold_train, def_splits['target_train'])\n",
    "\n",
    "  k_rf_model.fit(k_sel_X_train, def_splits['target_train'])\n",
    "\n",
    "  k_sel_cols = def_threshold_train.columns[selector.get_support()]\n",
    "  k_sel_X_test = def_threshold_test[k_sel_cols]\n",
    "  score = round(k_rf_model.score(k_sel_X_test.values, def_splits['target_test'] ), 3)\n",
    "\n",
    "  score_list.append(score)\n",
    "print(score_list, score_list.index(max(score_list)))\n",
    "num_of_feat = score_list.index(max(score_list)) # find the highest score. We will use  that as the value of k\n",
    "\n",
    "selector = SelectKBest(mutual_info_regression, k=num_of_feat+1)\n",
    "selector.fit_transform(def_threshold_train, def_splits['target_train'])\n",
    "\n",
    "sel_feats = selector.get_feature_names_out()\n",
    "k_sel_X_train = def_threshold_train[sel_feats]\n",
    "k_sel_X_test = def_threshold_test[sel_feats]\n",
    "\n",
    "##### Model (KBest)\n",
    "\n",
    "###### Linear Model\n",
    "\n",
    "\n",
    "KBest_def_lin_reg = Linear_regression(k_sel_X_train, k_sel_X_test,\n",
    "                               def_splits['target_train'], def_splits['target_test'])\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "def_evaluation_stats = def_evaluation_stats.assign(KBest_def_lin_reg =  [KBest_def_lin_reg['train_RMSE'], KBest_def_lin_reg['test_RMSE'], KBest_def_lin_reg['cv_rmse'], KBest_def_lin_reg['R2_train'], KBest_def_lin_reg['R2_test']])\n",
    "\n",
    "def_evaluation_stats\n",
    "\n",
    "###### DecisionTree Model\n",
    "\n",
    "KBest_def_dt_reg = DecisionTreeRegression(k_sel_X_train, k_sel_X_test,\n",
    "                               def_splits['target_train'], def_splits['target_test'])\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "def_evaluation_stats = def_evaluation_stats.assign(KBest_def_dt_reg = [KBest_def_dt_reg['train_RMSE'], KBest_def_dt_reg['test_RMSE'], KBest_def_dt_reg['cv_rmse'], KBest_def_dt_reg['R2_train'], KBest_def_dt_reg['R2_test']])\n",
    "\n",
    "def_evaluation_stats\n",
    "\n",
    "\n",
    "\n",
    "###### RandomForest Model\n",
    "\n",
    "hyperparameters = {\"criterion\": 'friedman_mse', \"max_depth\": 8, \"max_features\": 'sqrt', \"n_estimators\": 20}\n",
    "KBest_def_rf_reg = RandomForestRegression(k_sel_X_train, k_sel_X_test,\n",
    "                               def_splits['target_train'], def_splits['target_test'], hyperparameters)\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "def_evaluation_stats = def_evaluation_stats.assign(KBest_def_rf_reg = [KBest_def_rf_reg['train_RMSE'], KBest_def_rf_reg['test_RMSE'], KBest_def_rf_reg['cv_rmse'], KBest_def_rf_reg['R2_train'], KBest_def_rf_reg['R2_test']])\n",
    "\n",
    "def_evaluation_stats\n",
    "\n",
    "###### XgBoost Model\n",
    "\n",
    "hyperparameters = {'learning_rate': 0.02, 'max_depth': 4, 'n_estimators': 150}\n",
    "KBest_def_xgb_reg = XGBoostRegression(k_sel_X_train, k_sel_X_test, def_splits['target_train'], def_splits['target_test'], hyperparameters)\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "def_evaluation_stats = def_evaluation_stats.assign(KBest_def_xgb_reg = [KBest_def_xgb_reg['train_RMSE'], KBest_def_xgb_reg['test_RMSE'], KBest_def_xgb_reg['cv_rmse'], KBest_def_xgb_reg['R2_train'], KBest_def_xgb_reg['R2_test']])\n",
    "def_evaluation_stats\n",
    "\n",
    "#### Mutual Information\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "# def_sel_X_train\n",
    "mutual_info = mutual_info_regression(k_sel_X_train, def_splits['target_train'])\n",
    "mutual_info\n",
    "\n",
    "mutual_info = pd.Series(mutual_info)\n",
    "mutual_info.index = k_sel_X_train.columns\n",
    "mutual_info.sort_values(ascending=False)\n",
    "\n",
    "mutual_info.sort_values(ascending=False).plot.bar(figsize=(15,5))\n",
    "\n",
    "##### Select to 20% perct\n",
    "\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "\n",
    "## Selecting the top 20 percentile\n",
    "selected_top_columns = SelectPercentile(mutual_info_regression, percentile=50)\n",
    "selected_top_columns.fit(k_sel_X_train, def_splits['target_train'])\n",
    "\n",
    "selected_top_columns.get_support()\n",
    "\n",
    "def_20_columns = k_sel_X_train.columns[selected_top_columns.get_support()]\n",
    "\n",
    "def_20_train = k_sel_X_train[def_20_columns]\n",
    "def_20_test = k_sel_X_test[def_20_columns]\n",
    "\n",
    "\n",
    "##### Model (MI)\n",
    "\n",
    "###### Linear Model\n",
    "\n",
    "\n",
    "MI_def_lin_reg = Linear_regression(def_20_train, def_20_test,\n",
    "                               def_splits['target_train'], def_splits['target_test'])\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "def_evaluation_stats = def_evaluation_stats.assign(MI_def_lin_reg =  [MI_def_lin_reg['train_RMSE'], MI_def_lin_reg['test_RMSE'], MI_def_lin_reg['cv_rmse'], MI_def_lin_reg['R2_train'], MI_def_lin_reg['R2_test']])\n",
    "\n",
    "def_evaluation_stats\n",
    "\n",
    "###### DecisionTree Model\n",
    "\n",
    "MI_def_dt_reg = DecisionTreeRegression(def_20_train, def_20_test,\n",
    "                               def_splits['target_train'], def_splits['target_test'])\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "def_evaluation_stats = def_evaluation_stats.assign(MI_def_dt_reg = [MI_def_dt_reg['train_RMSE'], MI_def_dt_reg['test_RMSE'], MI_def_dt_reg['cv_rmse'], MI_def_dt_reg['R2_train'], MI_def_dt_reg['R2_test']])\n",
    "\n",
    "def_evaluation_stats\n",
    "\n",
    "\n",
    "\n",
    "###### RandomForest Model\n",
    "\n",
    "hyperparameters = {\"criterion\": 'friedman_mse', \"max_depth\": 8, \"max_features\": 'sqrt', \"n_estimators\": 20}\n",
    "MI_def_rf_reg = RandomForestRegression(def_20_train, def_20_test,\n",
    "                               def_splits['target_train'], def_splits['target_test'], hyperparameters)\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "def_evaluation_stats = def_evaluation_stats.assign(MI_def_rf_reg = [MI_def_rf_reg['train_RMSE'], MI_def_rf_reg['test_RMSE'], MI_def_rf_reg['cv_rmse'], MI_def_rf_reg['R2_train'], MI_def_rf_reg['R2_test']])\n",
    "\n",
    "def_evaluation_stats\n",
    "\n",
    "###### XgBoost Model\n",
    "\n",
    "hyperparameters = {'learning_rate': 0.02, 'max_depth': 4, 'n_estimators': 150}\n",
    "MI_def_xgb_reg = XGBoostRegression(k_sel_X_train, k_sel_X_test, def_splits['target_train'], def_splits['target_test'], hyperparameters)\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "def_evaluation_stats = def_evaluation_stats.assign(MI_def_xgb_reg = [MI_def_xgb_reg['train_RMSE'], MI_def_xgb_reg['test_RMSE'], MI_def_xgb_reg['cv_rmse'], MI_def_xgb_reg['R2_train'], MI_def_xgb_reg['R2_test']])\n",
    "def_evaluation_stats\n",
    "\n",
    "## Midfielders\n",
    "\n",
    "\n",
    "### VarianceThreshold\n",
    "\n",
    "VT_scaler = StandardScaler()\n",
    "df_mid_train_scaled = pd.DataFrame(VT_scaler.fit_transform(mid_splits['feature_train']), columns=mid_splits['feature_train'].columns)\n",
    "df_mid_test_scaled = pd.DataFrame(VT_scaler.transform(mid_splits['features_test']), columns=mid_splits['features_test'].columns)\n",
    "\n",
    "selector = VarianceThreshold(threshold = 0.1)\n",
    "selector.fit_transform(df_mid_train_scaled)\n",
    "\n",
    "mid_threshold_columns = df_mid_train_scaled.columns[selector.get_support()]\n",
    "\n",
    "mid_threshold_train = df_mid_train_scaled[mid_threshold_columns]\n",
    "mid_threshold_test = df_mid_test_scaled[mid_threshold_columns]\n",
    "\n",
    "mid_threshold_train.shape, mid_threshold_test.shape\n",
    "\n",
    "#### Model(VT)\n",
    "\n",
    "##### Linear Model\n",
    "\n",
    "\n",
    "VarT_mid_lin_reg = Linear_regression(mid_threshold_train, mid_threshold_test,\n",
    "                               mid_splits['target_train'], mid_splits['target_test'])\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "mid_evaluation_stats = mid_evaluation_stats.assign(VarT_mid_lin_reg =  [VarT_mid_lin_reg['train_RMSE'], VarT_mid_lin_reg['test_RMSE'], VarT_mid_lin_reg['cv_rmse'], VarT_mid_lin_reg['R2_train'], VarT_mid_lin_reg['R2_test']])\n",
    "\n",
    "mid_evaluation_stats\n",
    "\n",
    "##### DecisionTree Model\n",
    "\n",
    "VarT_mid_dt_reg = DecisionTreeRegression(mid_threshold_train, mid_threshold_test,\n",
    "                               mid_splits['target_train'], mid_splits['target_test'])\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "mid_evaluation_stats = mid_evaluation_stats.assign(VarT_mid_dt_reg = [VarT_mid_dt_reg['train_RMSE'], VarT_mid_dt_reg['test_RMSE'], VarT_mid_dt_reg['cv_rmse'], VarT_mid_dt_reg['R2_train'], VarT_mid_dt_reg['R2_test']])\n",
    "\n",
    "mid_evaluation_stats\n",
    "\n",
    "\n",
    "\n",
    "##### RandomForest Model\n",
    "\n",
    "hyperparameters = {\"criterion\": 'friedman_mse', \"max_depth\": 8, \"max_features\": 'sqrt', \"n_estimators\": 20}\n",
    "VarT_mid_rf_reg = RandomForestRegression(mid_threshold_train, mid_threshold_test,\n",
    "                               mid_splits['target_train'], mid_splits['target_test'], hyperparameters)\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "mid_evaluation_stats = mid_evaluation_stats.assign(VarT_mid_rf_reg = [VarT_mid_rf_reg['train_RMSE'], VarT_mid_rf_reg['test_RMSE'], VarT_mid_rf_reg['cv_rmse'], VarT_mid_rf_reg['R2_train'], VarT_mid_rf_reg['R2_test']])\n",
    "\n",
    "mid_evaluation_stats\n",
    "\n",
    "##### XgBoost Model\n",
    "\n",
    "hyperparameters = {'learning_rate': 0.02, 'max_depth': 4, 'n_estimators': 150}\n",
    "VarT_mid_xgb_reg = XGBoostRegression(mid_threshold_train, mid_threshold_test, mid_splits['target_train'], mid_splits['target_test'], hyperparameters)\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "mid_evaluation_stats = mid_evaluation_stats.assign(VarT_mid_xgb_reg = [VarT_mid_xgb_reg['train_RMSE'], VarT_mid_xgb_reg['test_RMSE'], VarT_mid_xgb_reg['cv_rmse'], VarT_mid_xgb_reg['R2_train'], VarT_mid_xgb_reg['R2_test']])\n",
    "mid_evaluation_stats\n",
    "\n",
    "### Feature selection techniques\n",
    "\n",
    "#### K-best features\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "\n",
    "k_rf_model = RandomForestRegressor(n_estimators=20,  max_depth=8, criterion='friedman_mse', max_features='sqrt', random_state=18)\n",
    "\n",
    "score_list  = []\n",
    "\n",
    "for k in range(1, 21):\n",
    "  selector = SelectKBest(mutual_info_regression, k=k)\n",
    "  k_sel_X_train =  selector.fit_transform(mid_threshold_train, mid_splits['target_train'])\n",
    "\n",
    "  k_rf_model.fit(k_sel_X_train, mid_splits['target_train'])\n",
    "\n",
    "  k_sel_cols = mid_threshold_train.columns[selector.get_support()]\n",
    "  k_sel_X_test = mid_threshold_test[k_sel_cols]\n",
    "  score = round(k_rf_model.score(k_sel_X_test.values, mid_splits['target_test'] ), 3)\n",
    "\n",
    "  score_list.append(score)\n",
    "print(score_list, score_list.index(max(score_list)))\n",
    "num_of_feat = score_list.index(max(score_list)) # find the highest score. We will use  that as the value of k\n",
    "\n",
    "selector = SelectKBest(mutual_info_regression, k=num_of_feat)\n",
    "selector.fit_transform(mid_threshold_train, mid_splits['target_train'])\n",
    "\n",
    "sel_feats = selector.get_feature_names_out()\n",
    "k_sel_X_train = mid_threshold_train[sel_feats]\n",
    "k_sel_X_test = mid_threshold_test[sel_feats]\n",
    "\n",
    "##### Model (KBest)\n",
    "\n",
    "###### Linear Model\n",
    "\n",
    "\n",
    "KBest_mid_lin_reg = Linear_regression(k_sel_X_train, k_sel_X_test,\n",
    "                               mid_splits['target_train'], mid_splits['target_test'])\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "mid_evaluation_stats = mid_evaluation_stats.assign(KBest_mid_lin_reg =  [KBest_mid_lin_reg['train_RMSE'], KBest_mid_lin_reg['test_RMSE'], KBest_mid_lin_reg['cv_rmse'], KBest_mid_lin_reg['R2_train'], KBest_mid_lin_reg['R2_test']])\n",
    "\n",
    "mid_evaluation_stats\n",
    "\n",
    "###### DecisionTree Model\n",
    "\n",
    "KBest_mid_dt_reg = DecisionTreeRegression(k_sel_X_train, k_sel_X_test,\n",
    "                               mid_splits['target_train'], mid_splits['target_test'])\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "mid_evaluation_stats = mid_evaluation_stats.assign(KBest_mid_dt_reg = [KBest_mid_dt_reg['train_RMSE'], KBest_mid_dt_reg['test_RMSE'], KBest_mid_dt_reg['cv_rmse'], KBest_mid_dt_reg['R2_train'], KBest_mid_dt_reg['R2_test']])\n",
    "\n",
    "mid_evaluation_stats\n",
    "\n",
    "\n",
    "\n",
    "###### RandomForest Model\n",
    "\n",
    "hyperparameters = {\"criterion\": 'friedman_mse', \"max_depth\": 8, \"max_features\": 'sqrt', \"n_estimators\": 20}\n",
    "KBest_mid_rf_reg = RandomForestRegression(k_sel_X_train, k_sel_X_test,\n",
    "                               mid_splits['target_train'], mid_splits['target_test'], hyperparameters)\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "mid_evaluation_stats = mid_evaluation_stats.assign(KBest_mid_rf_reg = [KBest_mid_rf_reg['train_RMSE'], KBest_mid_rf_reg['test_RMSE'], KBest_mid_rf_reg['cv_rmse'], KBest_mid_rf_reg['R2_train'], KBest_mid_rf_reg['R2_test']])\n",
    "\n",
    "mid_evaluation_stats\n",
    "\n",
    "###### XgBoost Model\n",
    "\n",
    "hyperparameters = {'learning_rate': 0.02, 'max_depth': 4, 'n_estimators': 150}\n",
    "KBest_mid_xgb_reg = XGBoostRegression(k_sel_X_train, k_sel_X_test, mid_splits['target_train'], mid_splits['target_test'], hyperparameters)\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "mid_evaluation_stats = mid_evaluation_stats.assign(KBest_mid_xgb_reg = [KBest_mid_xgb_reg['train_RMSE'], KBest_mid_xgb_reg['test_RMSE'], KBest_mid_xgb_reg['cv_rmse'], KBest_mid_xgb_reg['R2_train'], KBest_mid_xgb_reg['R2_test']])\n",
    "mid_evaluation_stats\n",
    "\n",
    "#### Mutual Information\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "# def_sel_X_train\n",
    "mutual_info = mutual_info_regression(k_sel_X_train, mid_splits['target_train'])\n",
    "mutual_info\n",
    "\n",
    "mutual_info = pd.Series(mutual_info)\n",
    "mutual_info.index = k_sel_X_train.columns\n",
    "mutual_info.sort_values(ascending=False)\n",
    "\n",
    "mutual_info.sort_values(ascending=False).plot.bar(figsize=(15,5))\n",
    "\n",
    "##### Select to 20% perct\n",
    "\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "\n",
    "## Selecting the top 20 percentile\n",
    "selected_top_columns = SelectPercentile(mutual_info_regression, percentile=50)\n",
    "selected_top_columns.fit(k_sel_X_train, mid_splits['target_train'])\n",
    "\n",
    "selected_top_columns.get_support()\n",
    "\n",
    "mid_20_columns = k_sel_X_train.columns[selected_top_columns.get_support()]\n",
    "\n",
    "mid_20_train = k_sel_X_train[mid_20_columns]\n",
    "mid_20_test = k_sel_X_test[mid_20_columns]\n",
    "\n",
    "\n",
    "##### Model (MI)\n",
    "\n",
    "###### Linear Model\n",
    "\n",
    "\n",
    "MI_mid_lin_reg = Linear_regression(mid_20_train, mid_20_test,\n",
    "                               mid_splits['target_train'], mid_splits['target_test'])\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "mid_evaluation_stats = mid_evaluation_stats.assign(MI_mid_lin_reg =  [MI_mid_lin_reg['train_RMSE'], MI_mid_lin_reg['test_RMSE'], MI_mid_lin_reg['cv_rmse'], MI_mid_lin_reg['R2_train'], MI_mid_lin_reg['R2_test']])\n",
    "\n",
    "mid_evaluation_stats\n",
    "\n",
    "###### DecisionTree Model\n",
    "\n",
    "MI_mid_dt_reg = DecisionTreeRegression(mid_20_train, mid_20_test,\n",
    "                               mid_splits['target_train'], mid_splits['target_test'])\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "mid_evaluation_stats = mid_evaluation_stats.assign(MI_mid_dt_reg = [MI_mid_dt_reg['train_RMSE'], MI_mid_dt_reg['test_RMSE'], MI_mid_dt_reg['cv_rmse'], MI_mid_dt_reg['R2_train'], MI_mid_dt_reg['R2_test']])\n",
    "\n",
    "mid_evaluation_stats\n",
    "\n",
    "\n",
    "\n",
    "###### RandomForest Model\n",
    "\n",
    "hyperparameters = {\"criterion\": 'friedman_mse', \"max_depth\": 8, \"max_features\": 'sqrt', \"n_estimators\": 20}\n",
    "MI_mid_rf_reg = RandomForestRegression(mid_20_train, mid_20_test,\n",
    "                               mid_splits['target_train'], mid_splits['target_test'], hyperparameters)\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "mid_evaluation_stats = mid_evaluation_stats.assign(MI_mid_rf_reg = [MI_mid_rf_reg['train_RMSE'], MI_mid_rf_reg['test_RMSE'], MI_mid_rf_reg['cv_rmse'], MI_mid_rf_reg['R2_train'], MI_mid_rf_reg['R2_test']])\n",
    "\n",
    "mid_evaluation_stats\n",
    "\n",
    "###### XgBoost Model\n",
    "\n",
    "hyperparameters = {'learning_rate': 0.02, 'max_depth': 4, 'n_estimators': 150}\n",
    "MI_mid_xgb_reg = XGBoostRegression(k_sel_X_train, k_sel_X_test, mid_splits['target_train'], mid_splits['target_test'], hyperparameters)\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "mid_evaluation_stats = mid_evaluation_stats.assign(MI_mid_xgb_reg = [MI_mid_xgb_reg['train_RMSE'], MI_mid_xgb_reg['test_RMSE'], MI_mid_xgb_reg['cv_rmse'], MI_mid_xgb_reg['R2_train'], MI_mid_xgb_reg['R2_test']])\n",
    "mid_evaluation_stats\n",
    "\n",
    "\n",
    "\n",
    "## Forwards\n",
    "\n",
    "\n",
    "### VarianceThreshold\n",
    "\n",
    "VT_scaler = StandardScaler()\n",
    "df_for_train_scaled = pd.DataFrame(VT_scaler.fit_transform(for_splits['feature_train']), columns=for_splits['feature_train'].columns)\n",
    "df_for_test_scaled = pd.DataFrame(VT_scaler.transform(for_splits['features_test']), columns=for_splits['features_test'].columns)\n",
    "\n",
    "selector = VarianceThreshold(threshold = 0.1)\n",
    "selector.fit_transform(df_for_train_scaled)\n",
    "\n",
    "for_threshold_columns = df_for_train_scaled.columns[selector.get_support()]\n",
    "\n",
    "for_threshold_train = df_for_train_scaled[for_threshold_columns]\n",
    "for_threshold_test = df_for_test_scaled[for_threshold_columns]\n",
    "\n",
    "for_threshold_train.shape, for_threshold_test.shape\n",
    "\n",
    "#### Model(VT)\n",
    "\n",
    "##### Linear Model\n",
    "\n",
    "\n",
    "VarT_for_lin_reg = Linear_regression(for_threshold_train, for_threshold_test,\n",
    "                               for_splits['target_train'], for_splits['target_test'])\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "for_evaluation_stats = for_evaluation_stats.assign(VarT_for_lin_reg =  [VarT_for_lin_reg['train_RMSE'], VarT_for_lin_reg['test_RMSE'], VarT_for_lin_reg['cv_rmse'], VarT_for_lin_reg['R2_train'], VarT_for_lin_reg['R2_test']])\n",
    "\n",
    "for_evaluation_stats\n",
    "\n",
    "##### DecisionTree Model\n",
    "\n",
    "VarT_for_dt_reg = DecisionTreeRegression(for_threshold_train, for_threshold_test,\n",
    "                               for_splits['target_train'], for_splits['target_test'])\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "for_evaluation_stats = for_evaluation_stats.assign(VarT_for_dt_reg = [VarT_for_dt_reg['train_RMSE'], VarT_for_dt_reg['test_RMSE'], VarT_for_dt_reg['cv_rmse'], VarT_for_dt_reg['R2_train'], VarT_for_dt_reg['R2_test']])\n",
    "\n",
    "for_evaluation_stats\n",
    "\n",
    "\n",
    "\n",
    "##### RandomForest Model\n",
    "\n",
    "hyperparameters = {\"criterion\": 'friedman_mse', \"max_depth\": 8, \"max_features\": 'sqrt', \"n_estimators\": 20}\n",
    "VarT_for_rf_reg = RandomForestRegression(for_threshold_train, for_threshold_test,\n",
    "                               for_splits['target_train'], for_splits['target_test'], hyperparameters)\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "for_evaluation_stats = for_evaluation_stats.assign(VarT_for_rf_reg = [VarT_for_rf_reg['train_RMSE'], VarT_for_rf_reg['test_RMSE'], VarT_for_rf_reg['cv_rmse'], VarT_for_rf_reg['R2_train'], VarT_for_rf_reg['R2_test']])\n",
    "\n",
    "for_evaluation_stats\n",
    "\n",
    "##### XgBoost Model\n",
    "\n",
    "hyperparameters = {'learning_rate': 0.02, 'max_depth': 4, 'n_estimators': 150}\n",
    "VarT_for_xgb_reg = XGBoostRegression(for_threshold_train, for_threshold_test, for_splits['target_train'], for_splits['target_test'], hyperparameters)\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "for_evaluation_stats = for_evaluation_stats.assign(VarT_for_xgb_reg = [VarT_for_xgb_reg['train_RMSE'], VarT_for_xgb_reg['test_RMSE'], VarT_for_xgb_reg['cv_rmse'], VarT_for_xgb_reg['R2_train'], VarT_for_xgb_reg['R2_test']])\n",
    "for_evaluation_stats\n",
    "\n",
    "### Feature selection techniques\n",
    "\n",
    "#### K-best features\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "\n",
    "k_rf_model = RandomForestRegressor(n_estimators=20,  max_depth=8, criterion='friedman_mse', max_features='sqrt', random_state=18)\n",
    "\n",
    "score_list  = []\n",
    "\n",
    "for k in range(1, 21):\n",
    "  selector = SelectKBest(mutual_info_regression, k=k)\n",
    "  k_sel_X_train =  selector.fit_transform(for_threshold_train, for_splits['target_train'])\n",
    "\n",
    "  k_rf_model.fit(k_sel_X_train, for_splits['target_train'])\n",
    "\n",
    "  k_sel_cols = for_threshold_train.columns[selector.get_support()]\n",
    "  k_sel_X_test = for_threshold_test[k_sel_cols]\n",
    "  score = round(k_rf_model.score(k_sel_X_test.values, for_splits['target_test'] ), 3)\n",
    "\n",
    "  score_list.append(score)\n",
    "print(score_list, score_list.index(max(score_list)))\n",
    "num_of_feat = score_list.index(max(score_list)) # find the highest score. We will use  that as the value of k\n",
    "\n",
    "selector = SelectKBest(mutual_info_regression, k=num_of_feat)\n",
    "selector.fit_transform(for_threshold_train, for_splits['target_train'])\n",
    "\n",
    "sel_feats = selector.get_feature_names_out()\n",
    "k_sel_X_train = for_threshold_train[sel_feats]\n",
    "k_sel_X_test = for_threshold_test[sel_feats]\n",
    "\n",
    "##### Model (KBest)\n",
    "\n",
    "###### Linear Model\n",
    "\n",
    "\n",
    "KBest_for_lin_reg = Linear_regression(k_sel_X_train, k_sel_X_test,\n",
    "                               for_splits['target_train'], for_splits['target_test'])\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "for_evaluation_stats = for_evaluation_stats.assign(KBest_for_lin_reg =  [KBest_for_lin_reg['train_RMSE'], KBest_for_lin_reg['test_RMSE'], KBest_for_lin_reg['cv_rmse'], KBest_for_lin_reg['R2_train'], KBest_for_lin_reg['R2_test']])\n",
    "\n",
    "for_evaluation_stats\n",
    "\n",
    "###### DecisionTree Model\n",
    "\n",
    "KBest_for_dt_reg = DecisionTreeRegression(k_sel_X_train, k_sel_X_test,\n",
    "                               for_splits['target_train'], for_splits['target_test'])\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "for_evaluation_stats = for_evaluation_stats.assign(KBest_for_dt_reg = [KBest_for_dt_reg['train_RMSE'], KBest_for_dt_reg['test_RMSE'], KBest_for_dt_reg['cv_rmse'], KBest_for_dt_reg['R2_train'], KBest_for_dt_reg['R2_test']])\n",
    "\n",
    "for_evaluation_stats\n",
    "\n",
    "\n",
    "\n",
    "###### RandomForest Model\n",
    "\n",
    "hyperparameters = {\"criterion\": 'friedman_mse', \"max_depth\": 8, \"max_features\": 'sqrt', \"n_estimators\": 20}\n",
    "KBest_for_rf_reg = RandomForestRegression(k_sel_X_train, k_sel_X_test,\n",
    "                               for_splits['target_train'], for_splits['target_test'], hyperparameters)\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "for_evaluation_stats = for_evaluation_stats.assign(KBest_for_rf_reg = [KBest_for_rf_reg['train_RMSE'], KBest_for_rf_reg['test_RMSE'], KBest_for_rf_reg['cv_rmse'], KBest_for_rf_reg['R2_train'], KBest_for_rf_reg['R2_test']])\n",
    "\n",
    "for_evaluation_stats\n",
    "\n",
    "###### XgBoost Model\n",
    "\n",
    "hyperparameters = {'learning_rate': 0.02, 'max_depth': 4, 'n_estimators': 150}\n",
    "KBest_for_xgb_reg = XGBoostRegression(k_sel_X_train, k_sel_X_test, for_splits['target_train'], for_splits['target_test'], hyperparameters)\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "for_evaluation_stats = for_evaluation_stats.assign(KBest_for_xgb_reg = [KBest_for_xgb_reg['train_RMSE'], KBest_for_xgb_reg['test_RMSE'], KBest_for_xgb_reg['cv_rmse'], KBest_for_xgb_reg['R2_train'], KBest_for_xgb_reg['R2_test']])\n",
    "for_evaluation_stats\n",
    "\n",
    "#### Mutual Information\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "# def_sel_X_train\n",
    "mutual_info = mutual_info_regression(k_sel_X_train, for_splits['target_train'])\n",
    "mutual_info\n",
    "\n",
    "mutual_info = pd.Series(mutual_info)\n",
    "mutual_info.index = k_sel_X_train.columns\n",
    "mutual_info.sort_values(ascending=False)\n",
    "\n",
    "mutual_info.sort_values(ascending=False).plot.bar(figsize=(15,5))\n",
    "\n",
    "##### Select to 20% perct\n",
    "\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "\n",
    "## Selecting the top 20 percentile\n",
    "selected_top_columns = SelectPercentile(mutual_info_regression, percentile=50)\n",
    "selected_top_columns.fit(k_sel_X_train, for_splits['target_train'])\n",
    "\n",
    "selected_top_columns.get_support()\n",
    "\n",
    "for_20_columns = k_sel_X_train.columns[selected_top_columns.get_support()]\n",
    "\n",
    "for_20_train = k_sel_X_train[for_20_columns]\n",
    "for_20_test = k_sel_X_test[for_20_columns]\n",
    "\n",
    "\n",
    "##### Model (MI)\n",
    "\n",
    "###### Linear Model\n",
    "\n",
    "\n",
    "MI_for_lin_reg = Linear_regression(for_20_train, for_20_test,\n",
    "                               for_splits['target_train'], for_splits['target_test'])\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "for_evaluation_stats = for_evaluation_stats.assign(MI_for_lin_reg =  [MI_for_lin_reg['train_RMSE'], MI_for_lin_reg['test_RMSE'], MI_for_lin_reg['cv_rmse'], MI_for_lin_reg['R2_train'], MI_for_lin_reg['R2_test']])\n",
    "\n",
    "for_evaluation_stats\n",
    "\n",
    "###### DecisionTree Model\n",
    "\n",
    "MI_for_dt_reg = DecisionTreeRegression(for_20_train, for_20_test,\n",
    "                               for_splits['target_train'], for_splits['target_test'])\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "for_evaluation_stats = for_evaluation_stats.assign(MI_for_dt_reg = [MI_for_dt_reg['train_RMSE'], MI_for_dt_reg['test_RMSE'], MI_for_dt_reg['cv_rmse'], MI_for_dt_reg['R2_train'], MI_for_dt_reg['R2_test']])\n",
    "\n",
    "for_evaluation_stats\n",
    "\n",
    "\n",
    "\n",
    "###### RandomForest Model\n",
    "\n",
    "hyperparameters = {\"criterion\": 'friedman_mse', \"max_depth\": 8, \"max_features\": 'sqrt', \"n_estimators\": 20}\n",
    "MI_for_rf_reg = RandomForestRegression(for_20_train, for_20_test,\n",
    "                               for_splits['target_train'], for_splits['target_test'], hyperparameters)\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "for_evaluation_stats = for_evaluation_stats.assign(MI_for_rf_reg = [MI_for_rf_reg['train_RMSE'], MI_for_rf_reg['test_RMSE'], MI_for_rf_reg['cv_rmse'], MI_for_rf_reg['R2_train'], MI_for_rf_reg['R2_test']])\n",
    "\n",
    "for_evaluation_stats\n",
    "\n",
    "###### XgBoost Model\n",
    "\n",
    "hyperparameters = {'learning_rate': 0.02, 'max_depth': 4, 'n_estimators': 150}\n",
    "MI_for_xgb_reg = XGBoostRegression(k_sel_X_train, k_sel_X_test, for_splits['target_train'], for_splits['target_test'], hyperparameters)\n",
    "\n",
    "# Store the model evaluation details in a DataFrame\n",
    "for_evaluation_stats = for_evaluation_stats.assign(MI_for_xgb_reg = [MI_for_xgb_reg['train_RMSE'], MI_for_xgb_reg['test_RMSE'], MI_for_xgb_reg['cv_rmse'], MI_for_xgb_reg['R2_train'], MI_for_xgb_reg['R2_test']])\n",
    "for_evaluation_stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FPL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
